{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58dd0c0f",
   "metadata": {},
   "source": [
    "# 1. 모듈 및 분석 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee837fab",
   "metadata": {},
   "source": [
    "### - 1. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad18520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#딥러닝 네트워크 기본구성 요소\n",
    "import torch.nn as nn\n",
    "\n",
    "#딥러닝에 자주 사용되는 함수 모듈\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#가중치 추정에 필요한 최적화 알고리즘\n",
    "import torch.optim as optim\n",
    "\n",
    "#데이터셋 과 모델 구조 및 이미지 변환 기술\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#데이터 차트 및 시각화\n",
    "#주피터노트북은 브라우저에서 보기위해 inline 필수\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af41fe",
   "metadata": {},
   "source": [
    "### - 2. 분석 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7477e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device is cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ngpu : cuda\\ncpu : cpu\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print('Current cuda device is', device)\n",
    "'''\n",
    "gpu : cuda\n",
    "cpu : cpu\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1bd46",
   "metadata": {},
   "source": [
    "### - 3. Hyper Parameter 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf5a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "batch_size : 모델 가중치를 한 번 업데이트 시킬 때 사용되는 샘플 단위 개수\n",
    "epoch_num : 학습 데이터를 모두 사용하여 학습하는 기본 단위 횟수\n",
    "learning_rate : 가중치 업데이트의 정도\n",
    "'''\n",
    "batch_size = 50\n",
    "epoch_num = 15\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6254a8",
   "metadata": {},
   "source": [
    "# 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b667b44",
   "metadata": {},
   "source": [
    "### - 1. MNIST 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be65dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data :  60000\n",
      "number of test data :  10000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "root : MNIST 데이터를 저장할 물리적 공간 위치\n",
    "train : True/False의 논리값으로 데이터를 학습용으로 사용할 것인지 지정\n",
    "download : True를 입력하면 root 옵션에서 지정된 위치에 데이터 저장.\n",
    "           처음 시행이 아니고 이미 저장된 데이터가 있다면 False\n",
    "transform : MNIST 데이터를 저장과 동시에 전처리를 할 수 있는 옵션\n",
    "            PyTorch는 입력 데이터로 Tensor를 사용하므로 이미지를 Tensor로 변형하는\n",
    "            전처리 transforms.ToTensor() 사용\n",
    "'''\n",
    "train_data = datasets.MNIST(root = './data', train = True, download = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root = './data', train = False,\n",
    "                          transform = transforms.ToTensor())\n",
    "\n",
    "print('number of training data : ', len(train_data))\n",
    "print('number of test data : ', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e9707",
   "metadata": {},
   "source": [
    "### - 2. MNIST 데이터 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2993e24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "MNIST는 3차원텐서임(1, 28, 28)\n",
    "squeeze() 함수는 크기가 1인 차원을 없앰\n",
    "'''\n",
    "\n",
    "image, label = train_data[0]\n",
    "\n",
    "plt.imshow(image.squeeze().numpy(), cmap = 'gray')\n",
    "plt.title('label : %s' % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099e84ff",
   "metadata": {},
   "source": [
    "### - 3. 미니 배치 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e93feec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name            | type                      | size\n",
      "Num of Batch    |                           | 1200\n",
      "first_batch     | <class 'list'>            | 2\n",
      "first_batch[0]  | <class 'torch.Tensor'>    | torch.Size([50, 1, 28, 28])\n",
      "first_batch[1]  | <class 'torch.Tensor'>    | torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "dataset : 미니 배치로구성할 데이터\n",
    "batch_size : 미니 배치의 사이즈\n",
    "shuffle: 시계열 데이터가 아닌 경우, 데이터의 순서에 대해서는 학습하지 못하도록 랜덤으로 섞음\n",
    "torch_size[50, 1, 28,28] : batch_size, channel, width, height\n",
    "\n",
    "'''\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = True)\n",
    "\n",
    "first_batch = train_loader.__iter__().__next__()\n",
    "print('{:15s} | {:<25} | {}'.format('name','type', 'size'))\n",
    "print('{:15s} | {:<25} | {}'.format('Num of Batch','', \n",
    "                                   len(train_loader)))\n",
    "print('{:15s} | {:<25} | {}'.format('first_batch',str(type(first_batch)), \n",
    "                                   len(first_batch)))\n",
    "print('{:15s} | {:<25} | {}'.format('first_batch[0]',\n",
    "                                    str(type(first_batch[0])), \n",
    "                                    first_batch[0].shape))\n",
    "print('{:15s} | {:<25} | {}'.format('first_batch[1]',\n",
    "                                    str(type(first_batch[1])), \n",
    "                                    first_batch[1].shape))\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c802c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Module 상속받는 CNN클래스 정의\n",
    "class CNN(nn.Module):\n",
    "    # 가중치 정의\n",
    "    def __init__(self):\n",
    "        # nn.Module 클래서 속성을 상속받고 초기화\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # in_channels = 1 : tensor의 채널 크기\n",
    "        # out_channels = 32 : conv1의 출력크기. conv2의 입력크기와 같아야함\n",
    "        # kernel_size = 3 : Filter의 크기. \n",
    "        #                   Scalar 값으로 지정하면 가로와 세로의 크기가 같은 2D Filter 생성\n",
    "        #                   kernel_size = 3 은 (3x3)Filter임\n",
    "        # stride = 1 : Filter가 움직이는 단위\n",
    "        # padding : 옵션을 지정하지 않아 padding = 0이 적용되어 시행되지 않음\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        \n",
    "        # 0.25 확률의 dropout1 지정\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        # 0.5 확률의 dropout1 지정\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        \n",
    "        # Fully-connected Layer 정의\n",
    "        # in_features = 9216, out_features = 128\n",
    "        # 9216 크기의 벡터를 128 크기의 벡터로 변환하는 가중치 설계\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        # fc1 에서 출력된 128 크기의 벡터를 MNIST의 클래스 개수인 10 크기의 벡터로 변환\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "        \n",
    "    # Feed Forward 연산 정의\n",
    "    def forward(self, x):\n",
    "        # 입력 이미지 conv1 레이어 통과\n",
    "        x = self.conv1(x)\n",
    "        # ReLU 활성함수 적용\n",
    "        # 활성 함수는 단순 연산이므로 __init__에서 정의한 학습 가중치 없음\n",
    "        x = F.relu(x)\n",
    "        # conv2 레이어 통과\n",
    "        x = self.conv2(x)\n",
    "        # ReLU 활성함수 적용\n",
    "        x = F.relu(x)\n",
    "        # (2x2) 크기의 filter로 max pooling 적용\n",
    "        # pooling layer는 단순연산이므로 학습할 가중치 없음\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # 0.25 확률의 dropout1 적용\n",
    "        x = self.dropout1(x)\n",
    "        # Fully-connected Layer 통과하기전, 고차원의 Tensor를 1차원의 벡터로 변환\n",
    "        # 2개의 Convolutional Layer와 1번의 max pooling으로 만들어진 [64, 12, 12]크기의 3차원 Tensor가 9216벡터로 변환됨\n",
    "        x = torch.flatten(x, 1)\n",
    "        # 9216 크기의 벡터를 128 크기의 벡터로 학습하는 fc1 통과\n",
    "        x = self.fc1(x)\n",
    "        # ReLU 활성함수 적용\n",
    "        x = F.relu(x)\n",
    "        # 0.5 확률의 dropout2 적용\n",
    "        x = self.dropout2(x)\n",
    "        # 2번째 Fully-connected Layer인 fc2를 통과하면서 벡터의 사이즈가 128에서 10으로 줄어듦\n",
    "        x = self.fc2(x)\n",
    "        # 최종 출력값으로 log-softmax 계산\n",
    "        # softmax보다 연산 속도를 높일 수 있음\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164534c7",
   "metadata": {},
   "source": [
    "### - 4. Optimizer 및 손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53ecbf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 클래스를 이용해 model이라는 인스턴스 생성\n",
    "# 1-2에서 지정한 device 인식\n",
    "model = CNN().to(device)\n",
    "\n",
    "# 손실 함수를 최소로 하는 가중치를 찾기 위해 Adam 알고리즘의 optimizer 지정\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# MNIST는 다중 클래스 분류 문제이기에 교차 엔트로피(CrossEntropy)를 손실 함수로 설정\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694c02d3",
   "metadata": {},
   "source": [
    "### - 5. 설계한 CNN 모형 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69fe85ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dbb395",
   "metadata": {},
   "source": [
    "### - 6. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9736cb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rk401\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 0/tLoss: 2.291\n",
      "Train Step: 1000/tLoss: 0.381\n",
      "Train Step: 2000/tLoss: 0.200\n",
      "Train Step: 3000/tLoss: 0.180\n",
      "Train Step: 4000/tLoss: 0.108\n",
      "Train Step: 5000/tLoss: 0.034\n",
      "Train Step: 6000/tLoss: 0.140\n",
      "Train Step: 7000/tLoss: 0.038\n",
      "Train Step: 8000/tLoss: 0.077\n",
      "Train Step: 9000/tLoss: 0.029\n",
      "Train Step: 10000/tLoss: 0.015\n",
      "Train Step: 11000/tLoss: 0.082\n",
      "Train Step: 12000/tLoss: 0.005\n",
      "Train Step: 13000/tLoss: 0.075\n",
      "Train Step: 14000/tLoss: 0.066\n",
      "Train Step: 15000/tLoss: 0.029\n",
      "Train Step: 16000/tLoss: 0.017\n",
      "Train Step: 17000/tLoss: 0.004\n"
     ]
    }
   ],
   "source": [
    "# CNN클래스가 저장된 model 인스턴스를 학습 모드로 실행할 것을 명시\n",
    "model.train()\n",
    "# 보조 인덱스 지정\n",
    "i = 0\n",
    "\n",
    "# 미리 지정해둔 epoch 수만큼 반복 학습 for문 선언\n",
    "for epoch in range(epoch_num):\n",
    "    # 학습 데이터를 batch_size로 나눈 만큼 반복 수행\n",
    "    # train_loader는 매 시행마다 미니 배치의 데이터와 정답을 data와 target에 저장\n",
    "    for data, target in train_loader:\n",
    "        # 미니 배치의 데이터를 기존에 지정한 장비 device에 할당\n",
    "        data = data.to(device)\n",
    "        # 미니 배치의 정답을 기존에 지정한 장비 device에 할당\n",
    "        target = target.to(device)\n",
    "        # 학습 시작 전, 이전 반복 시행에서 저장된 optimizer의 gradient 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 미니 배치 데이터를 모델에 통과시키는 Feed Forward 연산으로 결괏값 계산\n",
    "        output = model(data)\n",
    "        # 계산된 결괏값과 실제 정답으로 손실 함수 계산\n",
    "        loss = criterion(output,target)\n",
    "        # 손실 함수를 통해 Gradient 계산\n",
    "        loss.backward()\n",
    "        # 위에서 계산된 Gradient를 통해 모델의 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 1000번째 시행마다 손실 함수를 확인하기 위한 if문\n",
    "        if i % 1000 == 0:\n",
    "            # 손실 함수 출력\n",
    "            print('Train Step: {}/tLoss: {:.3f}'.format(i, loss.item()))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fd961",
   "metadata": {},
   "source": [
    "### - 7. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd5db465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set : Accuracy : 98.96%\n"
     ]
    }
   ],
   "source": [
    "# 평가 모드 실행\n",
    "# eval 함수를 호출하면 Dropout이 적용되지 않고 Batch-Normalization도 평가모드로 전환됨\n",
    "model.eval()\n",
    "# 정답 개수를 저장할 변수\n",
    "correct = 0\n",
    "\n",
    "# 테스트 데니터를 batch_size로 나눈 만큼 반복 수행됨\n",
    "# test_loader는 매 시행마다 미니 배치의 데이터와 정답을 data와 target에 저장\n",
    "for data, target in test_loader:\n",
    "    # 미니 배치의 데이터를 기존에 저장한 장비 device에 할당\n",
    "    data = data.to(device)\n",
    "    # 미니 배치의 정답을 기존에 지정한 장비 device에 할당\n",
    "    target = target.to(device)\n",
    "    # 미니 배치 데이터를 모델에 통과시켜 결괏값 계산\n",
    "    output = model(data)\n",
    "    # Log-Softmax 값이 가장 큰 인덱스를 예측값으로 저장\n",
    "    prediction = output.data.max(1)[1]\n",
    "    # 실제 정답과 예측값이 같으면 True, 다르면 False인 논리값으로 구성된 벡터 더하기\n",
    "    # 미니 배치 중 정답의개수를구하고 반복 시행마다 누적해서 더해줌\n",
    "    correct += prediction.eq(target.data).sum()\n",
    "    \n",
    "# 전체 테스트 데이터 중 맞춘 개수의 비율을 통해 정확도 계산하여 출력    \n",
    "print('Test set : Accuracy : {:.2f}%'.format(100 * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4612733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
